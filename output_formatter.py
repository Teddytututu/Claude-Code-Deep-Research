"""
Output Formatter for Research Reports v7.0
Generates bilingual markdown reports (Chinese + English)

Author: Deep Research System
Date: 2026-02-09
"""

from typing import Dict, Any, List
from pathlib import Path
from datetime import datetime
import json


class ReportFormatter:
    """
    Formats research findings into bilingual markdown reports

    Output specification:
    - Chinese narrative + English terminology
    - Clickable citations for all references
    - ≥ 10,000 words (Chinese + English mixed)
    - Structured sections with comprehensive analysis
    """

    def __init__(self):
        self.template = self._load_template()

    def _load_template(self) -> str:
        """Load report template"""
        return """# {topic_en} - Deep Research Monograph / {topic_cn} 深度研究报告

> **Research Session**: {session_id}
> **Date**: {date}
> **Orchestration**: {orchestration_pattern}
> **Query**: {query}

---

## Executive Summary / 执行摘要

{executive_summary}

---

## Theoretical Framework / 理论框架

{theoretical_framework}

---

## Academic Landscape / 学术版图

{academic_landscape}

### Root Papers / 根基论文

{root_papers}

### SOTA Works / 最先进工作

{sota_works}

### Survey Papers / 综述论文

{survey_papers}

### Citation Network / 引用网络

{citation_network}

---

## Open Source Ecosystem / 开源生态

{open_source_ecosystem}

### Technology Factions / 技术流派

{technology_factions}

### Architecture Patterns / 架构模式

{architecture_patterns}

### Representative Projects / 代表项目

{representative_projects}

---

## Community Perspectives / 社区观点

{community_perspectives}

### Consensus Points / 社区共识

{consensus_points}

### Controversial Topics / 争议话题

{controversial_topics}

### Practical Recommendations / 实践建议

{practical_recommendations}

---

## Performance Analysis / 性能分析

### Estimated Costs / 预估成本

{cost_analysis}

- **Token Usage**: {total_tokens:,} tokens ({token_multiplier}x single-agent)
- **Estimated Cost**: ${estimated_cost}
- **Coordination Overhead**: {coordination_overhead} potential interactions

### Success Probability / 成功概率

{success_analysis}

- **Single-agent Baseline**: {single_agent_success_rate}%
- **Expected Improvement**: +90.2% (Anthropic research)
- **Multi-agent Threshold**: 45% (Google/MIT rule)

### Efficiency Metrics / 效率指标

{efficiency_metrics}

- **Single Agent**: 67 tasks/1K tokens
- **Multi-Agent**: 14-21 tasks/1K tokens (69-79% less efficient)

---

## Framework Recommendation / 框架推荐

Based on Chinese community consensus: "AutoGen快、CrewAI稳、LangGraph强"

### Recommended Framework / 推荐框架

{framework_recommendation}

### Selection Criteria / 选择标准

```
Simple/Quick → Swarm (Educational only, NOT production-ready)
State-heavy → LangGraph (8% overhead, ~400 companies)
Team flow → CrewAI (24% overhead, 2 weeks to production)
Research → Custom orchestration with parallel subagents
```

### Production Metrics / 生产指标

{production_metrics}

---

## Critical Synthesis / 综合分析

### Cross-Domain Insights / 跨域洞察

{cross_domain_insights}

### Future Directions / 未来方向

{future_directions}

### Open Questions / 开放问题

{open_questions}

---

## References / 参考文献

{references}

---

## Appendix / 附录

### Research Methodology / 研究方法

{methodology}

### Data Sources / 数据来源

{data_sources}

### Limitations / 局限性

{limitations}

---

*Report generated by Deep Research System v7.0 | {generation_time}*
"""

    def format_paper_citation(self, paper: Dict[str, Any]) -> str:
        """
        Format academic paper citation with clickable links

        Format: [arXiv:ID](URL) | [PDF](PDF_URL)
        """
        arxiv_id = paper.get("arxiv_id", "")
        title = paper.get("title", "")

        if arxiv_id:
            url = f"https://arxiv.org/abs/{arxiv_id}"
            pdf_url = f"https://arxiv.org/pdf/{arxiv_id}.pdf"
            return f"- **{title}** [{arxiv_id}]({url}) | [PDF]({pdf_url})"
        else:
            return f"- **{title}**"

    def format_github_citation(self, project: Dict[str, Any]) -> str:
        """
        Format GitHub project citation with clickable links

        Format: [org/repo](URL) ⭐ Xk+
        """
        name = project.get("name", "")
        stars = project.get("stars_display", "⭐ ?")

        if "/" in name:
            url = f"https://github.com/{name}"
            return f"- [{name}]({url}) {stars}"
        else:
            return f"- **{name}** {stars}"

    def format_discussion_citation(self, discussion: Dict[str, Any]) -> str:
        """
        Format community discussion citation with clickable links

        Format: [Platform/Title](URL) (X upvotes)
        """
        platform = discussion.get("platform", "")
        url_markdown = discussion.get("url_markdown", "")
        title = discussion.get("title", "")

        if url_markdown:
            return f"- {url_markdown} - {title}"
        else:
            return f"- [{platform}] {title}"

    def generate_executive_summary(self, findings: Dict[str, Any]) -> str:
        """
        Generate executive summary with 8-12 key findings

        Each finding: Chinese description + English term + clickable citation
        """
        # This would be populated by the lead agent during synthesis
        # Placeholder for now
        return """*Key findings will be generated during synthesis phase*

**核心发现 / Key Findings:**

1. **Multi-Agent Coordination Patterns** / Multi-Agent 编排模式
   - Orchestration taxonomy evolved from centralized to hierarchical patterns
   - Coordination overhead scales at n(n-1)/2 interactions

2. **Token Cost Reality** / Token 成本现实
   - Multi-agent systems use 15x tokens vs single-agent (Anthropic research)
   - Performance gain: +90.2% but 69-79% less token-efficient

3. **Framework Selection** / 框架选择
   - Chinese community consensus: "AutoGen快、CrewAI稳、LangGraph强"
   - Each framework optimized for different use cases"""

    def format_academic_section(self, papers: List[Dict[str, Any]]) -> str:
        """Format academic papers section"""
        if not papers:
            return "No academic papers found."

        sections = {
            "root": [],
            "sota": [],
            "survey": []
        }

        for paper in papers:
            # Categorize papers (simplified)
            citation = self.format_paper_citation(paper)
            sections["sota"].append(citation)

        output = []
        if sections["root"]:
            output.append("#### Root Papers / 根基论文\n" + "\n".join(sections["root"]))
        if sections["sota"]:
            output.append("#### SOTA Works / 最先进工作\n" + "\n".join(sections["sota"]))
        if sections["survey"]:
            output.append("#### Survey Papers / 综述论文\n" + "\n".join(sections["survey"]))

        return "\n\n".join(output)

    def format_github_section(self, projects: List[Dict[str, Any]]) -> str:
        """Format GitHub projects section"""
        if not projects:
            return "No GitHub projects found."

        citations = [self.format_github_citation(p) for p in projects]
        return "\n".join(citations)

    def format_community_section(self, discussions: List[Dict[str, Any]]) -> str:
        """Format community discussions section"""
        if not discussions:
            return "No community discussions found."

        citations = [self.format_discussion_citation(d) for d in discussions]
        return "\n".join(citations)

    def format_performance_section(self, metrics: Dict[str, Any]) -> str:
        """Format performance analysis section"""
        total_tokens = metrics.get("total_tokens", 0)
        token_multiplier = metrics.get("token_multiplier", "15x")
        estimated_cost = metrics.get("estimated_cost", "$0.00")

        return f"""**Token Usage Breakdown:**
- Input tokens: {metrics.get('input_tokens', 0):,}
- Output tokens: {metrics.get('output_tokens', 0):,}
- Total: {total_tokens:,}

**Cost Analysis:**
- Estimated: {estimated_cost}
- Per 1M tokens: ${metrics.get('cost_per_1m', 15)}

**Efficiency:**
- Tasks per 1K tokens: {metrics.get('tasks_per_1k', 21)}
- Single-agent baseline: 67 tasks/1K tokens"""

    def generate_report(
        self,
        topic_en: str,
        topic_cn: str,
        findings: Dict[str, Any],
        output_path: str = "research_output"
    ) -> str:
        """
        Generate complete markdown report

        Args:
            topic_en: Topic in English
            topic_cn: Topic in Chinese
            findings: Research findings data
            output_path: Output directory path

        Returns:
            Path to generated report
        """
        # Create output directory
        output_dir = Path(output_path)
        output_dir.mkdir(exist_ok=True)

        # Prepare template variables
        session_id = findings.get("session_id", "unknown")[:8]
        date = datetime.now().strftime("%Y-%m-%d")
        query = findings.get("query", "")

        # Extract data from findings
        academic_papers = findings.get("academic_papers", [])
        github_projects = findings.get("github_projects", [])
        community_discussions = findings.get("community_discussions", [])
        performance_metrics = findings.get("performance_metrics", {})

        # Build report sections
        executive_summary = self.generate_executive_summary(findings)
        academic_landscape = self.format_academic_section(academic_papers)
        open_source_ecosystem = self.format_github_section(github_projects)
        community_perspectives = self.format_community_section(community_discussions)
        performance_analysis = self.format_performance_section(performance_metrics)

        # Format template
        report_content = self.template.format(
            topic_en=topic_en,
            topic_cn=topic_cn,
            session_id=session_id,
            date=date,
            orchestration_pattern="lead-researcher + parallel-subagents",
            query=query,
            executive_summary=executive_summary,
            theoretical_framework="*Theoretical framework analysis would be generated during synthesis*",
            academic_landscape=academic_landscape,
            root_papers="",
            sota_works=academic_landscape,
            survey_papers="",
            citation_network="",
            open_source_ecosystem=open_source_ecosystem,
            technology_factions="",
            architecture_patterns="",
            representative_projects=open_source_ecosystem,
            community_perspectives=community_perspectives,
            consensus_points="",
            controversial_topics="",
            practical_recommendations="",
            cost_analysis=performance_analysis,
            total_tokens=performance_metrics.get("total_tokens", 0),
            token_multiplier="15x",
            estimated_cost=performance_metrics.get("estimated_cost", "$0.00"),
            coordination_overhead="n(n-1)/2",
            success_analysis="",
            single_agent_success_rate="35",
            efficiency_metrics="",
            framework_recommendation="",
            production_metrics="",
            cross_domain_insights="",
            future_directions="",
            open_questions="",
            references="",
            methodology="",
            data_sources="",
            limitations="",
            generation_time=datetime.now().isoformat()
        )

        # Save report
        filename = f"{session_id}_{topic_en.lower().replace(' ', '_')}_report.md"
        report_path = output_dir / filename

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)

        # Also save JSON data
        json_path = output_dir / f"{session_id}_findings.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(findings, f, indent=2, ensure_ascii=False)

        return str(report_path)


# CLI interface
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Generate research report")
    parser.add_argument("--topic-en", type=str, required=True, help="Topic in English")
    parser.add_argument("--topic-cn", type=str, required=True, help="Topic in Chinese")
    parser.add_argument("--findings", type=str, required=True, help="Path to findings JSON")
    parser.add_argument("--output", type=str, default="research_output", help="Output directory")

    args = parser.parse_args()

    # Load findings
    with open(args.findings, 'r', encoding='utf-8') as f:
        findings = json.load(f)

    # Generate report
    formatter = ReportFormatter()
    report_path = formatter.generate_report(
        topic_en=args.topic_en,
        topic_cn=args.topic_cn,
        findings=findings,
        output_path=args.output
    )

    print(f"Report generated: {report_path}")
