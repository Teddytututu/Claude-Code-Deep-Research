"""
Output Formatter for Research Reports v7.0
Generates bilingual markdown reports (Chinese + English)

Author: Deep Research System
Date: 2026-02-09
"""

from typing import Dict, Any, List
from pathlib import Path
from datetime import datetime
import json


class ReportFormatter:
    """
    Formats research findings into bilingual markdown reports

    Output specification:
    - Chinese narrative + English terminology
    - Clickable citations for all references
    - â‰¥ 10,000 words (Chinese + English mixed)
    - Structured sections with comprehensive analysis
    """

    def __init__(self):
        self.template = self._load_template()

    def _load_template(self) -> str:
        """Load report template"""
        return """# {topic_en} - Deep Research Monograph / {topic_cn} æ·±åº¦ç ”ç©¶æŠ¥å‘Š

> **Research Session**: {session_id}
> **Date**: {date}
> **Orchestration**: {orchestration_pattern}
> **Query**: {query}

---

## Executive Summary / æ‰§è¡Œæ‘˜è¦

{executive_summary}

---

## Theoretical Framework / ç†è®ºæ¡†æž¶

{theoretical_framework}

---

## Academic Landscape / å­¦æœ¯ç‰ˆå›¾

{academic_landscape}

### Root Papers / æ ¹åŸºè®ºæ–‡

{root_papers}

### SOTA Works / æœ€å…ˆè¿›å·¥ä½œ

{sota_works}

### Survey Papers / ç»¼è¿°è®ºæ–‡

{survey_papers}

### Citation Network / å¼•ç”¨ç½‘ç»œ

{citation_network}

---

## Visualizations / å¯è§†åŒ–åˆ†æž

{visualization_section}

{visualization_embeds}

---

## Visualizations / å¯è§†åŒ–åˆ†æž

{visualization_section}

---

## Open Source Ecosystem / å¼€æºç”Ÿæ€

{open_source_ecosystem}

### Technology Factions / æŠ€æœ¯æµæ´¾

{technology_factions}

### Architecture Patterns / æž¶æž„æ¨¡å¼

{architecture_patterns}

### Representative Projects / ä»£è¡¨é¡¹ç›®

{representative_projects}

---

## Community Perspectives / ç¤¾åŒºè§‚ç‚¹

{community_perspectives}

### Consensus Points / ç¤¾åŒºå…±è¯†

{consensus_points}

### Controversial Topics / äº‰è®®è¯é¢˜

{controversial_topics}

### Practical Recommendations / å®žè·µå»ºè®®

{practical_recommendations}

---

## Performance Analysis / æ€§èƒ½åˆ†æž

### Estimated Costs / é¢„ä¼°æˆæœ¬

{cost_analysis}

- **Token Usage**: {total_tokens:,} tokens ({token_multiplier}x single-agent)
- **Estimated Cost**: ${estimated_cost}
- **Coordination Overhead**: {coordination_overhead} potential interactions

### Success Probability / æˆåŠŸæ¦‚çŽ‡

{success_analysis}

- **Single-agent Baseline**: {single_agent_success_rate}%
- **Expected Improvement**: +90.2% (Anthropic research)
- **Multi-agent Threshold**: 45% (Google/MIT rule)

### Efficiency Metrics / æ•ˆçŽ‡æŒ‡æ ‡

{efficiency_metrics}

- **Single Agent**: 67 tasks/1K tokens
- **Multi-Agent**: 14-21 tasks/1K tokens (69-79% less efficient)

---

## Framework Recommendation / æ¡†æž¶æŽ¨è

Based on Chinese community consensus: "AutoGenå¿«ã€CrewAIç¨³ã€LangGraphå¼º"

### Recommended Framework / æŽ¨èæ¡†æž¶

{framework_recommendation}

### Selection Criteria / é€‰æ‹©æ ‡å‡†

```
Simple/Quick â†’ Swarm (Educational only, NOT production-ready)
State-heavy â†’ LangGraph (8% overhead, ~400 companies)
Team flow â†’ CrewAI (24% overhead, 2 weeks to production)
Research â†’ Custom orchestration with parallel subagents
```

### Production Metrics / ç”Ÿäº§æŒ‡æ ‡

{production_metrics}

---

## Critical Synthesis / ç»¼åˆåˆ†æž

### Cross-Domain Insights / è·¨åŸŸæ´žå¯Ÿ

{cross_domain_insights}

### Future Directions / æœªæ¥æ–¹å‘

{future_directions}

### Open Questions / å¼€æ”¾é—®é¢˜

{open_questions}

---

## References / å‚è€ƒæ–‡çŒ®

{references}

---

## Appendix / é™„å½•

### Research Methodology / ç ”ç©¶æ–¹æ³•

{methodology}

### Data Sources / æ•°æ®æ¥æº

{data_sources}

### Limitations / å±€é™æ€§

{limitations}

---

*Report generated by Deep Research System v7.0 | {generation_time}*
"""

    def format_paper_citation(self, paper: Dict[str, Any]) -> str:
        """
        Format academic paper citation with clickable links

        Format: [arXiv:ID](URL) | [PDF](PDF_URL)
        """
        arxiv_id = paper.get("arxiv_id", "")
        title = paper.get("title", "")

        if arxiv_id:
            url = f"https://arxiv.org/abs/{arxiv_id}"
            pdf_url = f"https://arxiv.org/pdf/{arxiv_id}.pdf"
            return f"- **{title}** [{arxiv_id}]({url}) | [PDF]({pdf_url})"
        else:
            return f"- **{title}**"

    def format_github_citation(self, project: Dict[str, Any]) -> str:
        """
        Format GitHub project citation with clickable links

        Format: [org/repo](URL) â­ Xk+
        """
        name = project.get("name", "")
        stars = project.get("stars_display", "â­ ?")

        if "/" in name:
            url = f"https://github.com/{name}"
            return f"- [{name}]({url}) {stars}"
        else:
            return f"- **{name}** {stars}"

    def format_discussion_citation(self, discussion: Dict[str, Any]) -> str:
        """
        Format community discussion citation with clickable links

        Format: [Platform/Title](URL) (X upvotes)
        """
        platform = discussion.get("platform", "")
        url_markdown = discussion.get("url_markdown", "")
        title = discussion.get("title", "")

        if url_markdown:
            return f"- {url_markdown} - {title}"
        else:
            return f"- [{platform}] {title}"

    def generate_executive_summary(self, findings: Dict[str, Any]) -> str:
        """
        Generate executive summary with 8-12 key findings

        Each finding: Chinese description + English term + clickable citation
        """
        # This would be populated by the lead agent during synthesis
        # Placeholder for now
        return """*Key findings will be generated during synthesis phase*

**æ ¸å¿ƒå‘çŽ° / Key Findings:**

1. **Multi-Agent Coordination Patterns** / Multi-Agent ç¼–æŽ’æ¨¡å¼
   - Orchestration taxonomy evolved from centralized to hierarchical patterns
   - Coordination overhead scales at n(n-1)/2 interactions

2. **Token Cost Reality** / Token æˆæœ¬çŽ°å®ž
   - Multi-agent systems use 15x tokens vs single-agent (Anthropic research)
   - Performance gain: +90.2% but 69-79% less token-efficient

3. **Framework Selection** / æ¡†æž¶é€‰æ‹©
   - Chinese community consensus: "AutoGenå¿«ã€CrewAIç¨³ã€LangGraphå¼º"
   - Each framework optimized for different use cases"""

    def format_academic_section(self, papers: List[Dict[str, Any]]) -> str:
        """Format academic papers section"""
        if not papers:
            return "No academic papers found."

        sections = {
            "root": [],
            "sota": [],
            "survey": []
        }

        for paper in papers:
            # Categorize papers (simplified)
            citation = self.format_paper_citation(paper)
            sections["sota"].append(citation)

        output = []
        if sections["root"]:
            output.append("#### Root Papers / æ ¹åŸºè®ºæ–‡\n" + "\n".join(sections["root"]))
        if sections["sota"]:
            output.append("#### SOTA Works / æœ€å…ˆè¿›å·¥ä½œ\n" + "\n".join(sections["sota"]))
        if sections["survey"]:
            output.append("#### Survey Papers / ç»¼è¿°è®ºæ–‡\n" + "\n".join(sections["survey"]))

        return "\n\n".join(output)

    def format_github_section(self, projects: List[Dict[str, Any]]) -> str:
        """Format GitHub projects section"""
        if not projects:
            return "No GitHub projects found."

        citations = [self.format_github_citation(p) for p in projects]
        return "\n".join(citations)

    def format_community_section(self, discussions: List[Dict[str, Any]]) -> str:
        """Format community discussions section"""
        if not discussions:
            return "No community discussions found."

        citations = [self.format_discussion_citation(d) for d in discussions]
        return "\n".join(citations)

    def format_visualization_section(self, visualizations: Optional[Dict[str, str]] = None) -> str:
        """
        Format visualization section with embedded HTML.

        Args:
            visualizations: Dictionary of visualization name to HTML embed code

        Returns:
            Formatted visualization section
        """
        if not visualizations:
            return """
*Visualizations require the pyvis library. Install with:*
```bash
pip install pyvis
```
Then re-run the visualization generator.*
"""

        output = []

        if "citation_network" in visualizations:
            output.append("### Citation Network / å¼•ç”¨ç½‘ç»œ\n")
            output.append(visualizations["citation_network"])
            output.append("\n")

        if "cross_domain" in visualizations:
            output.append("### Cross-Domain Relationships / è·¨åŸŸå…³ç³»å›¾è°±\n")
            output.append(visualizations["cross_domain"])
            output.append("\n")
            output.append("""
**èŠ‚ç‚¹è¯´æ˜Ž / Node Legend:**
- ðŸ”µ è“è‰²åœ†å½¢ = Academic Paper / å­¦æœ¯è®ºæ–‡
- ðŸŸ¢ ç»¿è‰²æ–¹å½¢ = GitHub Repository / ä»£ç åº“
- ðŸŸ  æ©™è‰²è±å½¢ = Community Discussion / ç¤¾åŒºè®¨è®º
""")

        return "\n".join(output)

    def generate_visualizations(
        self,
        research_data_dir: str = "research_data",
        output_dir: str = "research_output/visualizations"
    ) -> Dict[str, str]:
        """
        Generate visualizations from research data.

        Args:
            research_data_dir: Directory containing research data JSON files
            output_dir: Directory for visualization outputs

        Returns:
            Dictionary of visualization names to HTML embed codes
        """
        try:
            from visualization import VisualizationBuilder

            builder = VisualizationBuilder(
                research_data_dir=research_data_dir,
                output_dir=output_dir
            )

            return builder.generate_all()

        except ImportError:
            print("Warning: visualization module not available")
            return {}
        except Exception as e:
            print(f"Warning: Failed to generate visualizations: {e}")
            return {}

    def format_performance_section(self, metrics: Dict[str, Any]) -> str:
        """Format performance analysis section"""
        total_tokens = metrics.get("total_tokens", 0)
        token_multiplier = metrics.get("token_multiplier", "15x")
        estimated_cost = metrics.get("estimated_cost", "$0.00")

        return f"""**Token Usage Breakdown:**
- Input tokens: {metrics.get('input_tokens', 0):,}
- Output tokens: {metrics.get('output_tokens', 0):,}
- Total: {total_tokens:,}

**Cost Analysis:**
- Estimated: {estimated_cost}
- Per 1M tokens: ${metrics.get('cost_per_1m', 15)}

**Efficiency:**
- Tasks per 1K tokens: {metrics.get('tasks_per_1k', 21)}
- Single-agent baseline: 67 tasks/1K tokens"""

    def generate_report(
        self,
        topic_en: str,
        topic_cn: str,
        findings: Dict[str, Any],
        output_path: str = "research_output",
        visualizations: Optional[Dict[str, str]] = None,
        research_data_dir: str = "research_data"
    ) -> str:
        """
        Generate complete markdown report

        Args:
            topic_en: Topic in English
            topic_cn: Topic in Chinese
            findings: Research findings data
            output_path: Output directory path
            visualizations: Pre-generated visualization embed codes
            research_data_dir: Directory for research data (to generate visualizations)

        Returns:
            Path to generated report
        """
        # Create output directory
        output_dir = Path(output_path)
        output_dir.mkdir(exist_ok=True)

        # Generate visualizations if not provided
        if visualizations is None:
            viz_output_dir = output_dir / "visualizations"
            visualizations = self.generate_visualizations(
                research_data_dir=research_data_dir,
                output_dir=str(viz_output_dir)
            )

        # Prepare template variables
        session_id = findings.get("session_id", "unknown")[:8]
        date = datetime.now().strftime("%Y-%m-%d")
        query = findings.get("query", "")

        # Extract data from findings
        academic_papers = findings.get("academic_papers", [])
        github_projects = findings.get("github_projects", [])
        community_discussions = findings.get("community_discussions", [])
        performance_metrics = findings.get("performance_metrics", {})

        # Build report sections
        executive_summary = self.generate_executive_summary(findings)
        academic_landscape = self.format_academic_section(academic_papers)
        open_source_ecosystem = self.format_github_section(github_projects)
        community_perspectives = self.format_community_section(community_discussions)
        performance_analysis = self.format_performance_section(performance_metrics)
        visualization_section = self.format_visualization_section(visualizations)
        visualization_embeds = ""  # Already included in visualization_section

        # Format template
        report_content = self.template.format(
            topic_en=topic_en,
            topic_cn=topic_cn,
            session_id=session_id,
            date=date,
            orchestration_pattern="lead-researcher + parallel-subagents",
            query=query,
            executive_summary=executive_summary,
            theoretical_framework="*Theoretical framework analysis would be generated during synthesis*",
            academic_landscape=academic_landscape,
            root_papers="",
            sota_works=academic_landscape,
            survey_papers="",
            citation_network="",
            visualization_section=visualization_section,
            visualization_embeds=visualization_embeds,
            open_source_ecosystem=open_source_ecosystem,
            technology_factions="",
            architecture_patterns="",
            representative_projects=open_source_ecosystem,
            community_perspectives=community_perspectives,
            consensus_points="",
            controversial_topics="",
            practical_recommendations="",
            cost_analysis=performance_analysis,
            total_tokens=performance_metrics.get("total_tokens", 0),
            token_multiplier="15x",
            estimated_cost=performance_metrics.get("estimated_cost", "$0.00"),
            coordination_overhead="n(n-1)/2",
            success_analysis="",
            single_agent_success_rate="35",
            efficiency_metrics="",
            framework_recommendation="",
            production_metrics="",
            cross_domain_insights="",
            future_directions="",
            open_questions="",
            references="",
            methodology="",
            data_sources="",
            limitations="",
            generation_time=datetime.now().isoformat()
        )

        # Save report
        filename = f"{session_id}_{topic_en.lower().replace(' ', '_')}_report.md"
        report_path = output_dir / filename

        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)

        # Also save JSON data
        json_path = output_dir / f"{session_id}_findings.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(findings, f, indent=2, ensure_ascii=False)

        return str(report_path)


# CLI interface
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Generate research report")
    parser.add_argument("--topic-en", type=str, required=True, help="Topic in English")
    parser.add_argument("--topic-cn", type=str, required=True, help="Topic in Chinese")
    parser.add_argument("--findings", type=str, required=True, help="Path to findings JSON")
    parser.add_argument("--output", type=str, default="research_output", help="Output directory")

    args = parser.parse_args()

    # Load findings
    with open(args.findings, 'r', encoding='utf-8') as f:
        findings = json.load(f)

    # Generate report
    formatter = ReportFormatter()
    report_path = formatter.generate_report(
        topic_en=args.topic_en,
        topic_cn=args.topic_cn,
        findings=findings,
        output_path=args.output
    )

    print(f"Report generated: {report_path}")
