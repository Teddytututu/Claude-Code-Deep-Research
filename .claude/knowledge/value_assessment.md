# Value Assessment Framework / ä»·å€¼è¯„ä¼°æ¡†æ¶

> **Purpose**: Define the four-dimensional value assessment system for research papers.
> **Usage**: Reference this file via `@knowledge:value_assessment.md`
> **Depends on**: `@knowledge:institution_patterns.md`
> **Version**: 1.0 (2026-02-19)

---

## Overview / æ¦‚è¿°

æœ¬æ–‡æ¡£å®šä¹‰äº†ç ”ç©¶è®ºæ–‡çš„**å››ç»´ä»·å€¼è¯„ä¼°ç³»ç»Ÿ**ï¼Œç”¨äºï¼š
1. è¯†åˆ«é«˜ä»·å€¼ç ”ç©¶ï¼ˆS/A/B/C åˆ†çº§ï¼‰
2. ç”Ÿæˆ Top Picks æ¨èåˆ—è¡¨
3. çªå‡ºæ–°å…´è¶‹åŠ¿å’Œè¡Œä¸šé‡‡ç”¨ä¿¡å·

**æ ¸å¿ƒå…¬å¼**:
```
Value Score = Impact(30%) + Innovation(25%) + Practicality(25%) + Timeliness(20%) + Institution_Boost
```

---

## VALUE_DIMENSIONS / å››ä¸ªè¯„ä¼°ç»´åº¦

### 1. ImpactScore (å½±å“åŠ›) - 30% æƒé‡

è¡¡é‡ç ”ç©¶çš„å¤–éƒ¨å½±å“å’Œå…³æ³¨ç¨‹åº¦ã€‚

| Metric | Description | Score Range |
|--------|-------------|-------------|
| `citation_velocity` | è¿‘ 6 ä¸ªæœˆå¼•ç”¨é€Ÿåº¦ (citations / months) | 0.0 - 1.0 |
| `github_stars` | å¦‚æœ‰ä»£ç å®ç°ï¼ŒGitHub æ˜Ÿæ ‡æ•° | 0.0 - 1.0 |
| `community_mentions` | ç¤¾åŒºè®¨è®ºçƒ­åº¦ï¼ˆReddit, HN, Twitterï¼‰ | 0.0 - 1.0 |
| `big_tech_backing` | å¤§å‚èƒŒä¹¦ï¼ˆæ¥è‡ª institution_patternsï¼‰ | 0 / 1 |

**è®¡ç®—å…¬å¼**:
```python
def calculate_impact_score(paper, github_data=None, community_data=None):
    """
    è®¡ç®—å½±å“åŠ›åˆ†æ•°

    Args:
        paper: è®ºæ–‡æ•°æ®
        github_data: GitHub ç›¸å…³æ•°æ®ï¼ˆå¯é€‰ï¼‰
        community_data: ç¤¾åŒºè®¨è®ºæ•°æ®ï¼ˆå¯é€‰ï¼‰

    Returns:
        float: 0.0 - 1.0
    """
    score = 0

    # å¼•ç”¨é€Ÿåº¦ (æƒé‡ 40%)
    citations = paper.get("citations", 0)
    months_since_publish = paper.get("months_since_publish", 1)
    citation_velocity = citations / max(months_since_publish, 1)
    # å½’ä¸€åŒ–: 10 citations/month = 1.0
    score += min(citation_velocity / 10, 1.0) * 0.40

    # GitHub æ˜Ÿæ ‡ (æƒé‡ 30%)
    if github_data:
        stars = github_data.get("stars", 0)
        # å½’ä¸€åŒ–: 1000 stars = 1.0
        score += min(stars / 1000, 1.0) * 0.30
    else:
        score += 0.15  # æ— ä»£ç æ—¶ç»™ä¸­ç­‰åˆ†

    # ç¤¾åŒºè®¨è®º (æƒé‡ 30%)
    if community_data:
        mentions = community_data.get("mention_count", 0)
        # å½’ä¸€åŒ–: 50 mentions = 1.0
        score += min(mentions / 50, 1.0) * 0.30
    else:
        score += 0.15

    return min(score, 1.0)
```

### 2. InnovationScore (åˆ›æ–°æ€§) - 25% æƒé‡

è¡¡é‡ç ”ç©¶çš„æ–°é¢–æ€§å’Œçªç ´ç¨‹åº¦ã€‚

| Metric | Description | Values |
|--------|-------------|--------|
| `novelty` | æ–°é¢–æ€§ | 0.0 - 1.0 |
| `breakthrough_level` | çªç ´ç¨‹åº¦ | incremental / significant / paradigm_shift |
| `first_of_kind` | æ˜¯å¦é¦–åˆ› | True / False |

**è®¡ç®—å…¬å¼**:
```python
def calculate_innovation_score(paper):
    """
    è®¡ç®—åˆ›æ–°æ€§åˆ†æ•°

    Returns:
        float: 0.0 - 1.0
    """
    score = 0

    # æ–°é¢–æ€§ (æƒé‡ 50%)
    novelty_indicators = [
        paper.get("novelty_keywords", []),  # æ–°æ–¹æ³•å…³é”®è¯
        paper.get("new_dataset", False),    # æ–°æ•°æ®é›†
        paper.get("new_benchmark", False),  # æ–°åŸºå‡†
        paper.get("new_task", False),       # æ–°ä»»åŠ¡å®šä¹‰
    ]
    novelty_count = sum(1 for ind in novelty_indicators if ind)
    score += min(novelty_count / 3, 1.0) * 0.50

    # çªç ´ç¨‹åº¦ (æƒé‡ 50%)
    breakthrough = paper.get("breakthrough_level", "incremental")
    breakthrough_scores = {
        "paradigm_shift": 1.0,
        "significant": 0.7,
        "incremental": 0.4
    }
    score += breakthrough_scores.get(breakthrough, 0.4) * 0.50

    return min(score, 1.0)
```

### 3. PracticalityScore (å®ç”¨æ€§) - 25% æƒé‡

è¡¡é‡ç ”ç©¶çš„å·¥ç¨‹å¯è¡Œæ€§å’Œåº”ç”¨ä»·å€¼ã€‚

| Metric | Description | Values |
|--------|-------------|--------|
| `engineering_readiness` | å·¥ç¨‹å°±ç»ªåº¦ | theory / prototype / production |
| `code_available` | ä»£ç å¯ç”¨æ€§ | True / False |
| `reproducibility` | å¯å¤ç°æ€§ | 0.0 - 1.0 |

**è®¡ç®—å…¬å¼**:
```python
def calculate_practicality_score(paper):
    """
    è®¡ç®—å®ç”¨æ€§åˆ†æ•°

    Returns:
        float: 0.0 - 1.0
    """
    score = 0

    # å·¥ç¨‹å°±ç»ªåº¦ (æƒé‡ 40%)
    readiness = paper.get("engineering_readiness", "theory")
    readiness_scores = {
        "production": 1.0,
        "prototype": 0.6,
        "theory": 0.3
    }
    score += readiness_scores.get(readiness, 0.3) * 0.40

    # ä»£ç å¯ç”¨æ€§ (æƒé‡ 30%)
    if paper.get("code_available", False) or paper.get("github_url"):
        score += 0.30
    else:
        score += 0.10

    # å¯å¤ç°æ€§ (æƒé‡ 30%)
    reproducibility = paper.get("reproducibility", 0.5)
    # åŸºäºæ˜¯å¦æœ‰è¯¦ç»†æ–¹æ³•æè¿°ã€è¶…å‚æ•°ã€æ•°æ®é›†é“¾æ¥ç­‰
    score += reproducibility * 0.30

    return min(score, 1.0)
```

### 4. TimelinessScore (æ—¶æ•ˆæ€§) - 20% æƒé‡

è¡¡é‡ç ”ç©¶çš„æ–°è¿‘åº¦å’Œè¶‹åŠ¿ç›¸å…³æ€§ã€‚

| Metric | Description | Values |
|--------|-------------|--------|
| `recency` | æ–°è¿‘åº¦ | 0.0 - 1.0 |
| `trend_acceleration` | è¶‹åŠ¿åŠ é€Ÿåº¦ | accelerating / stable / declining |

**è®¡ç®—å…¬å¼**:
```python
def calculate_timeliness_score(paper):
    """
    è®¡ç®—æ—¶æ•ˆæ€§åˆ†æ•°

    Returns:
        float: 0.0 - 1.0
    """
    from datetime import datetime

    score = 0

    # æ–°è¿‘åº¦ (æƒé‡ 60%)
    publish_date = paper.get("publish_date")
    if publish_date:
        current_year = datetime.now().year
        paper_year = publish_date.year if hasattr(publish_date, 'year') else int(publish_date[:4])
        years_old = current_year - paper_year

        if years_old <= 1:      # 2024-2025
            score += 1.0 * 0.60
        elif years_old == 2:    # 2023
            score += 0.8 * 0.60
        elif years_old == 3:    # 2022
            score += 0.6 * 0.60
        else:                   # æ›´æ—©
            score += 0.4 * 0.60
    else:
        score += 0.5 * 0.60

    # è¶‹åŠ¿åŠ é€Ÿåº¦ (æƒé‡ 40%)
    trend = paper.get("trend_acceleration", "stable")
    trend_scores = {
        "accelerating": 1.0,
        "stable": 0.6,
        "declining": 0.3
    }
    score += trend_scores.get(trend, 0.6) * 0.40

    return min(score, 1.0)
```

---

## COMPOSITE_VALUE_SCORE / ç»¼åˆè¯„åˆ†ç®—æ³•

### æƒé‡é…ç½®

```python
VALUE_WEIGHTS = {
    "impact": 0.30,
    "innovation": 0.25,
    "practicality": 0.25,
    "timeliness": 0.20
}
```

### ç»¼åˆè®¡ç®—å‡½æ•°

```python
from institution_patterns import identify_institution

def calculate_value_score(paper, github_data=None, community_data=None):
    """
    è®¡ç®—è®ºæ–‡çš„ç»¼åˆä»·å€¼è¯„åˆ†

    Args:
        paper: è®ºæ–‡æ•°æ®å­—å…¸
        github_data: GitHub ç›¸å…³æ•°æ®ï¼ˆå¯é€‰ï¼‰
        community_data: ç¤¾åŒºè®¨è®ºæ•°æ®ï¼ˆå¯é€‰ï¼‰

    Returns:
        dict: {
            "value_score": float,        # 0.0 - 1.0
            "value_tier": str,           # S/A/B/C
            "dimension_scores": dict,    # å››ç»´åˆ†æ•°
            "institution_info": dict     # æœºæ„ä¿¡æ¯
        }
    """
    # 1. è®¡ç®—å››ç»´åˆ†æ•°
    impact_score = calculate_impact_score(paper, github_data, community_data)
    innovation_score = calculate_innovation_score(paper)
    practicality_score = calculate_practicality_score(paper)
    timeliness_score = calculate_timeliness_score(paper)

    # 2. åŠ æƒåŸºç¡€åˆ†æ•°
    base_score = (
        impact_score * VALUE_WEIGHTS["impact"] +
        innovation_score * VALUE_WEIGHTS["innovation"] +
        practicality_score * VALUE_WEIGHTS["practicality"] +
        timeliness_score * VALUE_WEIGHTS["timeliness"]
    )

    # 3. è·å–æœºæ„åŠ æˆ
    institution_info = identify_institution(paper)
    institution_boost = institution_info.get("value_boost", 0)

    # 4. è®¡ç®—æœ€ç»ˆåˆ†æ•°ï¼ˆä¸Šé™ 1.0ï¼‰
    final_score = min(1.0, base_score + institution_boost)

    # 5. ç¡®å®šä»·å€¼å±‚çº§
    value_tier = get_value_tier(final_score)

    return {
        "value_score": round(final_score, 2),
        "value_tier": value_tier,
        "dimension_scores": {
            "impact_score": round(impact_score, 2),
            "innovation_score": round(innovation_score, 2),
            "practicality_score": round(practicality_score, 2),
            "timeliness_score": round(timeliness_score, 2)
        },
        "institution_info": institution_info
    }
```

### ä»·å€¼å±‚çº§ (Value Tiers)

```python
def get_value_tier(score):
    """
    æ ¹æ®åˆ†æ•°ç¡®å®šä»·å€¼å±‚çº§

    Args:
        score: 0.0 - 1.0 çš„åˆ†æ•°

    Returns:
        str: S / A / B / C
    """
    if score >= 0.85:
        return "S"  # å¿…è¯»ã€æœªæ¥è¶‹åŠ¿ã€è¡Œä¸šé£å‘æ ‡
    elif score >= 0.70:
        return "A"  # é«˜ä»·å€¼ã€æ¨èé˜…è¯»
    elif score >= 0.50:
        return "B"  # æœ‰ä»·å€¼ã€å‚è€ƒé˜…è¯»
    else:
        return "C"  # ä¸€èˆ¬å‚è€ƒ
```

### å±‚çº§æè¿°

| Tier | Score Range | Description | Report Treatment |
|------|-------------|-------------|------------------|
| **S** | 0.85 - 1.0 | å¿…è¯»ã€æœªæ¥è¶‹åŠ¿ã€è¡Œä¸šé£å‘æ ‡ | Executive Summary çªå‡ºå±•ç¤º |
| **A** | 0.70 - 0.84 | é«˜ä»·å€¼ã€æ¨èé˜…è¯» | Top Picks åˆ—è¡¨ |
| **B** | 0.50 - 0.69 | æœ‰ä»·å€¼ã€å‚è€ƒé˜…è¯» | æ­£æ–‡æåŠ |
| **C** | < 0.50 | ä¸€èˆ¬å‚è€ƒ | ä»…åœ¨ Works Cited |

---

## TREND_INDICATORS / è¶‹åŠ¿æŒ‡æ ‡

è¯†åˆ«æ–°å…´çƒ­ç‚¹å’Œè¶‹åŠ¿ï¼š

```python
def identify_trend_indicators(paper, all_papers, community_data=None):
    """
    è¯†åˆ«è¶‹åŠ¿æŒ‡æ ‡

    Args:
        paper: ç›®æ ‡è®ºæ–‡
        all_papers: æ‰€æœ‰è®ºæ–‡åˆ—è¡¨ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        community_data: ç¤¾åŒºè®¨è®ºæ•°æ®

    Returns:
        list: è¶‹åŠ¿æŒ‡æ ‡åˆ—è¡¨
    """
    indicators = []

    # 1. æ–°å…´çƒ­ç‚¹: 2024-2025 æ–°ä¸»é¢˜ï¼Œå¼•ç”¨å¢é•¿ > 50%
    if is_emerging_hotspot(paper, all_papers):
        indicators.append("emerging_hotspot")

    # 2. èŒƒå¼è½¬ç§»: æ–¹æ³•è®ºæ ¹æœ¬æ€§å˜åŒ–
    if paper.get("breakthrough_level") == "paradigm_shift":
        indicators.append("paradigm_shift")

    # 3. è¡Œä¸šé‡‡ç”¨: å¤§å‚å¼€å§‹é‡‡ç”¨
    institution_info = identify_institution(paper)
    if institution_info.get("institution_type") == "big_tech":
        indicators.append("industry_adoption")

    # 4. ç¤¾åŒºçƒ­è®®: ç¤¾åŒºè®¨è®ºçƒ­åº¦é«˜
    if community_data and community_data.get("mention_count", 0) > 30:
        indicators.append("community_hype")

    # 5. å¿«é€Ÿä¼ æ’­: å¼•ç”¨é€Ÿåº¦ > 5/month
    citation_velocity = paper.get("citations", 0) / max(paper.get("months_since_publish", 1), 1)
    if citation_velocity > 5:
        indicators.append("viral_spread")

    return indicators
```

### è¶‹åŠ¿æŒ‡æ ‡æè¿°

| Indicator | Description | Visual Marker |
|-----------|-------------|---------------|
| `emerging_hotspot` | æ–°å…´çƒ­ç‚¹ï¼Œå¼•ç”¨å¢é•¿ > 50% | ğŸ”¥ |
| `paradigm_shift` | æ–¹æ³•è®ºæ ¹æœ¬æ€§å˜åŒ– | ğŸ’¡ |
| `industry_adoption` | å¤§å‚å¼€å§‹é‡‡ç”¨ | ğŸ¢ |
| `community_hype` | ç¤¾åŒºè®¨è®ºçƒ­åº¦é«˜ | ğŸ“¢ |
| `viral_spread` | å¿«é€Ÿä¼ æ’­ï¼Œå¼•ç”¨é€Ÿåº¦ > 5/month | ğŸ“ˆ |

---

## TOP_PICKS_GENERATION / Top Picks ç”Ÿæˆ

### ç”Ÿæˆæ¨èåˆ—è¡¨

```python
def generate_top_picks(papers_with_scores):
    """
    ç”Ÿæˆ Top Picks æ¨èåˆ—è¡¨

    Args:
        papers_with_scores: åŒ…å«ä»·å€¼è¯„åˆ†çš„è®ºæ–‡åˆ—è¡¨

    Returns:
        dict: {
            "must_read": [...],      # S çº§
            "high_value": [...],     # A çº§
            "emerging_trends": [...], # æœ‰ emerging_hotspot æŒ‡æ ‡
            "foundational": [...]    # æ ¹åŸºè®ºæ–‡ï¼ˆé«˜è¢«å¼•æ—©æœŸå·¥ä½œï¼‰
        }
    """
    # æŒ‰ value_score æ’åº
    sorted_papers = sorted(
        papers_with_scores,
        key=lambda p: p.get("value_score", 0),
        reverse=True
    )

    top_picks = {
        "must_read": [],
        "high_value": [],
        "emerging_trends": [],
        "foundational": []
    }

    for paper in sorted_papers:
        arxiv_id = paper.get("arxiv_id")
        tier = paper.get("value_tier")
        trend_indicators = paper.get("trend_indicators", [])

        # S çº§: å¿…è¯»
        if tier == "S":
            top_picks["must_read"].append({
                "arxiv_id": arxiv_id,
                "title": paper.get("title"),
                "institution": paper.get("institution_backing"),
                "value_score": paper.get("value_score"),
                "reason": generate_recommendation_reason(paper)
            })

        # A çº§: é«˜ä»·å€¼
        if tier == "A":
            top_picks["high_value"].append({
                "arxiv_id": arxiv_id,
                "title": paper.get("title"),
                "value_score": paper.get("value_score")
            })

        # æ–°å…´è¶‹åŠ¿
        if "emerging_hotspot" in trend_indicators or "paradigm_shift" in trend_indicators:
            top_picks["emerging_trends"].append({
                "arxiv_id": arxiv_id,
                "title": paper.get("title"),
                "trend_type": "Hotspot" if "emerging_hotspot" in trend_indicators else "Paradigm Shift"
            })

        # æ ¹åŸºè®ºæ–‡
        if paper.get("type") == "root" or paper.get("citations", 0) > 100:
            top_picks["foundational"].append({
                "arxiv_id": arxiv_id,
                "title": paper.get("title"),
                "citations": paper.get("citations")
            })

    return top_picks

def generate_recommendation_reason(paper):
    """
    ç”Ÿæˆæ¨èç†ç”±
    """
    reasons = []

    if paper.get("institution_backing"):
        reasons.append(f"æœºæ„: {paper.get('institution_backing')}")

    trend_indicators = paper.get("trend_indicators", [])
    if "industry_adoption" in trend_indicators:
        reasons.append("å¤§å‚é‡‡ç”¨")
    if "emerging_hotspot" in trend_indicators:
        reasons.append("æ–°å…´çƒ­ç‚¹")
    if "paradigm_shift" in trend_indicators:
        reasons.append("èŒƒå¼è½¬ç§»")

    return " | ".join(reasons) if reasons else "é«˜ç»¼åˆè¯„åˆ†"
```

---

## EMERGING_HOTSPOT_DETECTION / æ–°å…´çƒ­ç‚¹æ£€æµ‹

```python
def is_emerging_hotspot(paper, all_papers):
    """
    æ£€æµ‹æ˜¯å¦ä¸ºæ–°å…´çƒ­ç‚¹

    æ¡ä»¶:
    1. å‘è¡¨æ—¶é—´åœ¨ 2024-2025
    2. ä¸»é¢˜ç›¸å…³è®ºæ–‡æ•°é‡åœ¨å¢é•¿
    3. å¼•ç”¨å¢é•¿ > 50%ï¼ˆç›¸å¯¹åŒç±»è®ºæ–‡ï¼‰
    """
    from datetime import datetime

    # æ¡ä»¶ 1: æ–°è¿‘åº¦
    publish_year = paper.get("year", 2020)
    if publish_year < 2024:
        return False

    # æ¡ä»¶ 2: åŒç±»è®ºæ–‡æ•°é‡
    paper_topic = paper.get("primary_topic", "")
    similar_papers = [p for p in all_papers if paper_topic in p.get("topics", [])]
    if len(similar_papers) < 3:
        return False

    # æ¡ä»¶ 3: å¼•ç”¨å¢é•¿
    avg_citations = sum(p.get("citations", 0) for p in similar_papers) / len(similar_papers)
    paper_citations = paper.get("citations", 0)

    growth_rate = (paper_citations - avg_citations) / max(avg_citations, 1)

    return growth_rate > 0.5  # 50% ä»¥ä¸Šå¢é•¿
```

---

## VALUE_RANKING_OUTPUT / ä»·å€¼æ’åè¾“å‡ºæ ¼å¼

### JSON Schema

```json
{
  "value_assessment": {
    "paper_value_scores": [
      {
        "arxiv_id": "2601.23265",
        "title": "PaperBanana",
        "value_score": 0.92,
        "value_tier": "S",
        "institution_backing": "Google",
        "institution_boost": 0.30,
        "dimension_scores": {
          "impact_score": 0.85,
          "innovation_score": 0.90,
          "practicality_score": 0.88,
          "timeliness_score": 0.95
        },
        "trend_indicators": ["emerging_hotspot", "industry_adoption"]
      }
    ],
    "value_ranking": [
      {"rank": 1, "arxiv_id": "2601.23265", "tier": "S"},
      {"rank": 2, "arxiv_id": "2602.03828", "tier": "A"}
    ],
    "top_picks": {
      "must_read": [
        {
          "arxiv_id": "2601.23265",
          "title": "PaperBanana",
          "institution": "Google",
          "value_score": 0.92,
          "reason": "æœºæ„: Google | å¤§å‚é‡‡ç”¨ | æ–°å…´çƒ­ç‚¹"
        }
      ],
      "high_value": [
        {"arxiv_id": "2602.03828", "title": "AutoFigure", "value_score": 0.78}
      ],
      "emerging_trends": [
        {"arxiv_id": "2601.23265", "title": "PaperBanana", "trend_type": "Hotspot"}
      ],
      "foundational": [
        {"arxiv_id": "2302.05543", "title": "Foundation Paper", "citations": 250}
      ]
    },
    "institution_distribution": {
      "big_tech": ["Google", "Microsoft"],
      "top_universities": ["MIT", "Stanford"],
      "star_authors": ["Author Name (H-index: 85)"]
    },
    "emerging_hotspots": [
      {
        "topic": "AI-generated scientific illustrations",
        "paper_count": 4,
        "growth_rate": "150%",
        "key_papers": ["2601.23265", "2602.03828"],
        "industry_backing": ["Google"]
      }
    ]
  }
}
```

---

## INTEGRATION_WITH_LOGIC_ANALYSIS / ä¸é€»è¾‘åˆ†æçš„é›†æˆ

ä»·å€¼è¯„ä¼°ç»“æœåº”é›†æˆåˆ° `logic_analysis.json` çš„ `value_assessment` å­—æ®µä¸­ï¼š

```python
def integrate_value_assessment(logic_analysis, papers_with_value_scores):
    """
    å°†ä»·å€¼è¯„ä¼°ç»“æœé›†æˆåˆ°é€»è¾‘åˆ†æ JSON
    """
    logic_analysis["value_assessment"] = {
        "paper_value_scores": papers_with_value_scores,
        "value_ranking": generate_value_ranking(papers_with_value_scores),
        "top_picks": generate_top_picks(papers_with_value_scores),
        "institution_distribution": analyze_institution_distribution(papers_with_value_scores),
        "emerging_hotspots": detect_emerging_hotspots(papers_with_value_scores)
    }
    return logic_analysis
```

---

## CHANGELOG

### v1.0 (2026-02-19)
- Initial release
- Four-dimensional value assessment (Impact, Innovation, Practicality, Timeliness)
- S/A/B/C tier classification
- Top Picks generation
- Trend indicators
- Emerging hotspot detection
